\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{float}
\usepackage{todonotes}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\newcommand{\arrowright}{$\,\to\,$}

\DeclareMathOperator{\atantwo}{atan2}
    
\begin{document}

\title{App-controlled LEGO robotic arm\\
{\footnotesize Project of lecture ''Mobile Computing'' (winter term 2018/2019)}
}

\author{
\IEEEauthorblockN{Christoph Ulrich}
\IEEEauthorblockA{%\textit{dept. name of organization (of Aff.)} \\
\textit{HTWG Konstanz}\\
Constance, Germany\\
christoph.ulrich@htwg-konstanz.de}
\and
\IEEEauthorblockN{Benjamin Schaefer}
\IEEEauthorblockA{%\textit{dept. name of organization (of Aff.)} \\
\textit{HTWG Konstanz}\\
Constance, Germany\\
benjamin.schaefer@htwg-konstanz.de}
}

\maketitle

\begin{abstract}
In this document, a method for building and controlling a robot arm using an Android APP is proposed. The Android phone and the NXT board are connected via WLAN, through an additional computer. From the Android app commands can be generated via buttons or a graphical interface, which are received by the NXT and the robot arm controls. The control of the arm is written in Python. As in robotics, the ROS framework is used for communication.
\end{abstract}

%\begin{IEEEkeywords}
%component, formatting, style, styling, insert
%\end{IEEEkeywords}\

\section{Introduction / Motivation}
\begin{itemize}
	\item control of a robotic arm is a fundamental task in robotics - easy hands-on experience for everybody to this fundamental robotic application with this paper and the created low cost LEGO 3-DoF (\textit{Degrees of Freedom}) robot arm  (incl. instructions)
	\item application and hardware could be used in basic lecture "Grundlagen der mobilen Robotik" to better understand robot kinematics, ROS and a bit of perception
	\item recycling of old and unused hardware of the robotics lab at the HTWG Konstanz
	\item typical industrial applications to control a robotic arm run on more powerful hardware and often offer a complicated and - for beginners - confusing GUI, \todo[author=Christoph, inline]{insert example(s)} so we developed an easy to use mobile application for Android platforms
	\item ROS because widely used, very modular/extensible and basic framework which almost every student starting with robotics has to get in touch with
\end{itemize}
\par

\todo[author=Christoph, inline]{new paragraph - description of background and main ''problem''}
\begin{itemize}
	\item which platform to choose for controlling the  arm and driving the motors (Arduino, Raspberry, etc.) - should consume as little energy as possible,  should be flexible and portable
	\todo[author=Christoph, inline]{note that in \ref{sec:platform}}
	\item another aspect \arrowright how should the application on the mobile device communication with the controlling device \arrowright BT, WiFi, (lost of steering commands due to radio lacks etc.)
	\item arm construction \arrowright not too many components, not too heavy so that the motors are able to drive the arm even with more than one joint and with gripper load (to demonstrate gripping)
	\item app \arrowright 
\end{itemize}
Constructing a robot arm generally leads to some difficulties.

\section{State of the Art}
Although current approaches such as in \cite{onlIEEEApp-Arm} already control robotic arms using an app, but here usually an Arduino or a Raspberry Pi is used to control the arm. However, no hardware that can be reused from the lab is used here, and no known robotic frameworks are used here, which makes an extension or a rebuild more sophisticated Arms made from Lego Technic as in \cite{onlNXT-2DOF} have already been built, but these only offer two DoF and can only lift very light objects due to the low gear ratio. However, in order to be able to show kinematics and the problems with robotic arms in teaching, at least three DoF are necessary.
Also some private projects like in \cite{onlHackster} show how to control a homemade arm via an app.
\section{Proposed Approach}\label{sec:approach}

\subsection{Requirements Engineering}\label{sec:requirements}
The app should have the ability to control the arm via a graphical interface. To control the joints individually, there should also be a possibility to adjust the individual joints via buttons or sliders. Since the servomotors are likely to drift there should be a way to re-calibrate the arm at any time.
\\\\
The arm should be completely controllable by means of an APP via ROS. Furthermore, the goal is to build the arm completely from Lego Technic. In addition, the arm should be kept as light as possible in order to lift light 3D printed objects. It should also have a comfortable size so that the arm can be demonstrated in the teaching.

\subsection{Platform Decision}\label{sec:platform}
Since the arm and the app should be used for teaching, there was a variety of hardware to choose from. In addition, one goal was to use existing and disused hardware. Thus, the decision quickly fell on the NXT bricks of Lego Mindstorm [1]. There are enough bricks as well as sensors and motors in the lab. In addition, from the existing Lego technology also the arm can be constructed. Since Lego Technic is made of lightweight plastic, the finished arm can also be taken to a lecture and presented.\\
There was also a choice of Raspberry Pi's or Arduinos, but here it would have been necessary to order hardware such as motors or parts for the arm.\\
Thus, it offered to use the Lego NXT's, since no hardware needs to be ordered here and disused hardware is used again.

\subsection{Arm Construction}\label{sec:construction}
\begin{figure}[bt] 
	\centering
	\includegraphics[width=\textwidth/2]{img/arm_full}
	\caption[caption]{Figure of the Lego Technic arm. The lower joint is marked in red and the upper joint in blue}
	\label{fig:arm_full}
\end{figure}
\begin{figure}[bt] 
	\centering
	\includegraphics[width=\textwidth/2]{img/control_arm.png}
	\caption[caption]{Activity diagram of the Arm}
\label{fig:activitiy_arm}
\end{figure}

The arm, which can be seen in Figure 1, was designed entirely from Lego Technic. For this purpose, 2 NXT bricks were used. In addition, 4 motors and a touch sensor were used. An NXT was used to control the two arm joints, as well as the gripper. Since the NXTs only have three ports for motors, a second NXT was needed to rotate the base.\\
The servomotors have a built-in rotation sensor with an accuracy of 1 degree. Since these servomotors only have a torque of about 12 N.cm, a translation has been built into the wrist joint so that the motors can move the arm. For this purpose, a translation of 1/42 was used at the lower joint (red circle). The engine's ratio at the upper joint (blue circle) was 2/25.\\
In order to keep the arm as light as possible and to relieve the engines, sensors on the arm itself were completely dispensed with. However, since the engines have to be initialized, a touch sensor has been installed on the base to initialize the first arm articulated. The initialization of the second joint was solved by the torque of the motors, as there is less weight of the arm.

\subsection{Algorithms}\label{sec:algorithms}
\begin{figure}[bt] 
	\centering
	\includegraphics[width=\textwidth/2]{img/calibration.png}
	\caption[caption]{Activity diagram of the calibration process}
\label{fig:calibration}
\end{figure}
The following describes the calibration procedure, which is shown in Figure 2. Since the servomotors can only be controlled by the effort and have no encoder, the starting position of the motors is unknown. Therefore, these must be calibrated. A touch sensor is used for the lower joint. The lower motor rotates until the touch sensor responds to a touch. Then the upper arm is calibrated. Here, the engines rotate with the least force so long, with which the motors can just turn until the joint is in the final position and the engines can not turn, because the effort is too great. In order not to burden the motors unnecessarily, the calibration process is terminated as soon as a certain delta has been exceeded. Finally, the same procedure is repeated for the gripper.

\subsubsection{Kinematics}\label{sec:kinematics}
In order to control the arm it is essential to solve either it's forward or inverse kinematics. For our application, we need both problems to be solved. Users of the application should be able to directly control each joint individually (forward kinematics) as well as to move the TCP into a desired position (inverse kinematics). We will first take a look at the calculation of the forward kinematics and then introduce a short geometric solution of the inverse kinematics for our 3-DoF arm.
\todo[author=Christoph, inline]{TCP - list of abbreviations may be necessary}
\todo[author=Beide, inline]{measurement of arm dimensions}
\par
The goal of forward kinematics is to determine the pose (position and orientation) of the TCP for a given set of joint angles. The pose of the TCP regarding the origin of the robot arm can be described as a concatenation of $n$ transformations, where $n$ is the number of joints, of which every one has its own coordinate system. For our case $n$ is 3:
\begin{equation}\label{eq:trans_matrix}
T_0^3 = T_0^1 * T_1^2 * T_2^3
\end{equation}
where $T_i^{i-1}$ is a transformation matrix according to the \textit{Denavit-Hartenberg} convention:
\begin{equation}\label{eq:dh-convention}
T_i^{i-1} = Tl(0,0,d_i) * R(z, \theta_i) * Tl(a_i,0,0) * R(x, \alpha_i)
\end{equation}
with $Tl$ being a translation matrix, $R$ a rotation matrix, $d_i$ a translation in z, $a_i$ a translation (for prismatic joints) in x, $\theta_i$ a rotation around z and $\alpha_i$ a constant tilt angle between both joints. In our case we don't use prismatic joints and there are no constant tilt angles between the joints (they are all variable). So equation \ref{eq:dh-convention} simplifies to 
\begin{equation}\label{eq:dh-convention-short}
T_i^{i-1} = Tl(0,0,d_i) * R(z, \theta_i)
\end{equation}
By solving equation \ref{eq:dh-convention-short} we get the following transformation matrix $T_i^{i-1}$ for the forward kinematics:
\[
\begin{matrix}
\cos(\theta_i) & -\sin(\theta_i) & 0 & l_i \cdot \cos(\theta_i)  \\
\sin(\theta_i) & \cos(\theta_i) & 0 & l_i \cdot \sin(\theta_i) \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{matrix}
\]
Finally, one generally can get the pose of the TCP in the world coordinate system (usually that means with reference to the coordinate system of the robot's base) by multiplying the concatenated transformation matrix \ref{eq:trans_matrix} built from the set of given joint angles $\theta_i$ and the known lengths of the arm parts $l_i$ with the origin of the base:
\begin{equation}\label{eq:tcp_goal}
p_{tcp} = T_0^3 * \begin{pmatrix}0\\0\\0\\1\end{pmatrix}
\end{equation}
Note that one has to use homogeneous coordinates here. Also one should remember that $p_{tcp}$ is the pose of the TCP-origin. Usually users want to get the gripping point of their tool - in this case just add the half of the gripper length to the x-direction to the vector in equation \ref{eq:tcp_goal}.
\\
\par

As we saw previously, forward kinematics is a function $f$ with reference to a set of joint angles $\theta_i$. The goal of inverse kinematics is to calculate a set of joint angles from a desired TCP-pose. So obviously what we are searching for is the inverse of $f$:

\begin{equation}
f^{-1}(\theta_0, \theta_1, ..., \theta_n)
\end{equation}
There are several possible approaches to this problem - it can be solved either by algebraic, numerical or geometrical methods. We will briefly explain a geometrical solution.

We have to find the rotation angles for the three joints given a specific pose of the end-effector.
Figure \ref{fig:yaw_calc} shows a schematic top view of the robot:

\begin{figure}[htbp]
	\centerline{\includegraphics[scale=0.3]{img/kin_yaw_arm_top_view.png}}
	\caption{Schemactic top view of the robot. The two arm parts are coloured. We are searching for rotation angle $\theta$ of the base joint.}
	\label{fig:yaw_calc}
\end{figure}

As one can see, $\theta_1$ can easily be calculated:
\begin{equation}
\theta_1 = \atantwo(y,x)
\end{equation}

Figure \ref{fig:q1_q2_calc} shows the schematic side view of the robot.

\begin{figure}[htbp]
	\centerline{\includegraphics[scale=0.4]{img/kin_q1_q2.png}}
	\caption{Schematic side view of the robot. Joint angles $q_1$ and $q_2$ can be calculated with the support angles $\alpha$, $\beta$ and $\chi$.}
	\label{fig:q1_q2_calc}
\end{figure}

First of all, $\alpha$ can be calculated by
\begin{equation}
\alpha = \atantwo(p_y, p_x)
\end{equation}

Then, the law of cosines is used to calculate $\beta$ and $\chi$.
\begin{equation}
\l_2^2 = |\textbf{p}|^2 - 2 \cdot l_1 \cdot |\textbf{p}| \cdot \cos(\beta)
\end{equation}
with $l_2$ being the length of arm 2. From this follows

\begin{equation}
\beta = \arccos(\frac{\l_1^2 + |\textbf{p}|^2 - l_2^2}{2 \cdot l_1 \cdot |\textbf{p}|})
\end{equation}

Furthermore

\begin{equation}
|\textbf{p}|^2 = l_2^2 + l_1^2 - 2 \cdot l_1 \cdot l_2 \cdot \cos(\chi)
\end{equation}

with $l_1$ being the length of arm 1. From this follows

\begin{equation}
\chi = \arccos(\frac{\l_1 + l_2 - |\textbf{p}|^2}{2 \cdot l_1 \cdot l_2})
\end{equation}

With having calculated $\alpha$, $\beta$ and $\chi$, one can easily get $\theta_2$ and $\theta_3$:

\begin{equation}
\theta_2 = \alpha - \beta
\end{equation}

\begin{equation}
\theta_3 = \pi - \chi
\end{equation}

\subsection{App Development}\label{sec:development}
\todo[author=Christoph, inline]{communication/process description, ROS, navigation strategy, ... }

\subsubsection{Joint Control Activity}
\todo[author=Benni, inline]{Screenshot}
This activity offers buttons to calibrate the whole arm and to control each of the joints directly.

\subsubsection{TCP Control Activity}
\todo[author=Benni, inline]{Screenshot}
This activity offers a GUI on which the robot arm is pictured (schematically). The user can tap on any point in a predefined operational area of the robot and thereby determining the next pose of the TCP. If the inverse kinematics module, whose theory was described in section \ref{sec:kinematics}, finds a valid configuration for this point, the angles are transmitted to the ActionClient Module (\ref{sec:actionclient}).

\subsubsection{Forward Kinematics}
This module takes an angle configuration and calculates the resulting TCP pose as described in section \ref{sec:kinematics}.

\subsubsection{Inverse Kinematics}
This module takes x- and y-coordinates and calculates a possible angle configuration as described in section \ref{sec:kinematics}.

\subsubsection{ROS ActionClient}\label{sec:actionclient}

\subsubsection{ROS ActionServer}

\subsubsection{ROS NXT Control Node}

\subsection{Expected Results}\label{sec:expectedresults}
\todo[author=Christoph, inline]{speed, accuracy, ...}

\section{Results}

\section{Conclusion}
The NXT can be used to control a robot arm with a smartphone from a remote location. The present scenario has several disadvantages, e.g. restrictions for cables and an additional computer.
By using ROS this scenario can be extended quickly, e.g. by multiple users or a second arm. Despite the rather coarse Lego Technic parts, the arm has a relatively high accuracy and is ideal for demonstrations or teaching.

\section{Further Work}
\begin{itemize}
	\item 3D graphics in App
	\item EV3
	\item algorithms
	\item external better sensors to optimize
\end{itemize}
In further work, the NXT could be exchanged for a LEGO EV3 brick. On the one hand, the EV3 has one additional port to connect a sensor/device. On the other hand, it offers a WiFi interface, which eliminates the need for a laptop as connection supplier between smartphone and arm.
Currently the app offers only a 2D view of the arm. For a better operation a 3D view could be developed.
Another important point would be to install more and better external sensors to achieve a higher positional accuracy of the arm.

\begin{thebibliography}{00}
\bibitem{onlLegoMindstorm} 
Lego Mindstorm - NXT,
\\\texttt{https://www.lego.com/de-de/mindstorms/downloads/nxt-software-download}
\bibitem{onlROS} 
ROS - Kinetic,
\\\texttt{http://wiki.ros.org/kinetic/Installation}
\bibitem{onlHackster} 
Arduino-Arm with android-app,
\\\texttt{https://www.hackster.io/slantconcepts/control-arduino-
	robot-arm-with-android-app-1c0d96}
\bibitem{onlArduinoArm} 
Robot-Arm-Arduino,
\\\texttt{https://www.instructables.com/id/Robot-Arm-Arduino-
	App/}
\bibitem{onlKuka}
Kuka-hrc-guide,
\\\texttt{https://www.kuka.com/en-us/products/robotics-
	systems/software/application-software/kuka-hrc-guide-
	app}
\bibitem{onlIEEEApp-Arm} 
K. Premkumar, K. Nigel ``Smart Phone Based Robotic Arm Control Using
Raspberry Pi, Android and Wi-Fi`` IEEE, March 2015
\bibitem{onlNXT-2DOF} 
Lego Technic 2DOF arm construction,
\\\texttt{http://www.nxtprograms.com/robot\_arm/steps.html}

\end{thebibliography}

\end{document}